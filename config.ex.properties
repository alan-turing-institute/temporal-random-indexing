#URI for accessing to the Azure Blob Container
storage.uri=
#Storage prefix in the Blob Container where tokenization file are stored
storage.prefix=
#Output directory for the co-occurrences matrices
dir.out=
#Temp directory
dir.tmp=
#Filter class used to filter tokens during the tokenization. This class must implement the interface di.uniba.it.tri.tokenizer.Filter
occ.filter=StandardFilterNoNumber
#Number of threads for multi-thread processing
thread.n=2
#Windows size for co-occurrences
winSize=5
#Directory where the dictionary is stored
dict.path=
#This will discard words that appear less than <int> times
dict.minOcc=200
#Use a portion of the whole dataset (1=whole dataset)
sampling.ratio=0.2
#Enable dataset sampling
sampling.enable=true
#Load information about the distribution of data across time in order to perform balanced sampling
sampling.file=data_size.tsv
#start date
date.start=199601
#end date
date.end=201305